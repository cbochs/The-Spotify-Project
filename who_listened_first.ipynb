{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id = 'notbobbobby'\n",
    "\n",
    "# GET PLAYLISTS\n",
    "# playlists = get_user_playlists(user_id, [discover_database=True])\n",
    "\n",
    "# GET TRACKS\n",
    "# tracks = get_user_tracks(user_id, playlists)\n",
    "\n",
    "# GET FEATURES\n",
    "# features = get_user_unique_tracks_and_features(user_id, tracks)\n",
    "\n",
    "# COMBINE INTO ONE DATAFRAME\n",
    "# df = pd.merge(tracks, playlists, how='outer', on=['playlist_id', 'playlist_name'])\n",
    "# df = pd.merge(df, features, how='outer', on=['track_id', 'track_name'])\n",
    "\n",
    "# Note: indieair showed missing songs, which indicates the discrepancies between\n",
    "#       total_tracks of the playlists and output number of tracks\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "def get_data(db, user, time, kind='library'):\n",
    "    if db == '_history':\n",
    "        path = os.path.expanduser(os.path.join(ROOT, db, user, '{}_{}_{}.json'.format(user, time, kind)))\n",
    "    else:\n",
    "        path = os.path.expanduser(os.path.join(ROOT, db, user, time, '{}_{}_{}.json'.format(user, time, kind)))\n",
    "    return pd.read_json(path, orient='records', lines=True)\n",
    "\n",
    "library = get_data('_db', 'notbobbobby', '2018-10-31')\n",
    "discover = get_data('_db', 'discover', '2018-10-31')\n",
    "\n",
    "history_n = get_data('_history', 'notbobbobby', '2018', kind='history')\n",
    "history_d = get_data('_history', 'deedanvy', '2018', kind='history')\n",
    "history_c = get_data('_history', 'c.bochulak', '2018', kind='history')\n",
    "history = pd.concat([history_n, history_d, history_c])\n",
    "\n",
    "from datetime import timedelta\n",
    "history['played_at'] = history['played_at'].apply(lambda t: t - timedelta(hours=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's begin by looking at duplicated songs\n",
    "\n",
    "dup = discover[discover.duplicated(subset=['track_id', 'discover_id'], keep=False)] \\\n",
    "    .groupby(['track_id', 'track_name', 'artists', 'discover_id']) \\\n",
    "    .agg({'track_id': 'count'}) \\\n",
    "    .rename({'track_id': 'occurrence'}, axis=1) \\\n",
    "    .reset_index() \\\n",
    "    .sort_values(by='occurrence', ascending=False) \\\n",
    "\n",
    "dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: cross-correlation\n",
    "# Table needs to look like: [track_id, track_name, artists, album] [first_occurrence, discover_id] [second_occurrence, discover_id]\n",
    "\n",
    "# REQUIRED: Sort tracks by created_at. Otherwise, duplicates WILL NOT be filtered correctly\n",
    "sorted_tracks = discover.sort_values(by='created_at', ascending=True).reset_index()\n",
    "\n",
    "# Sub-table: [track_id, track_name, artists, album] [first_occurrrence, discover_id]\n",
    "dup_first = sorted_tracks[\n",
    "    sorted_tracks.duplicated(subset='track_id', keep=False) &\n",
    "    ~sorted_tracks.duplicated(subset='track_id', keep='first')] \\\n",
    "        [['track_id', 'track_name', 'album', 'artists', 'created_at', 'discover_id']] \\\n",
    "        .rename({'created_at': 'first_occurrence', 'discover_id': 'first_id'}, axis=1)\n",
    "\n",
    "# Sub-table: [track_id, second_occurrence, discover_id]\n",
    "dup_second = sorted_tracks[\n",
    "    sorted_tracks.duplicated(subset='track_id', keep='first')] \\\n",
    "        [['track_id', 'created_at', 'discover_id']] \\\n",
    "        .rename({'created_at': 'second_occurrence', 'discover_id': 'second_id'}, axis=1)\n",
    "\n",
    "# Merge tables\n",
    "# REMOVE: all NaN results come from there being a 'first', but no 'second' occurrence\n",
    "timeline = pd \\\n",
    "    .merge(dup_first, dup_second, how='outer', on='track_id') \\\n",
    "    .dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = ['notbobbobby', 'deedanvy']\n",
    "colors = {\n",
    "    'notbobbobby': '#1DB954',\n",
    "    'deedanvy': '#883677',\n",
    "    'c.bochulak': '#16BAC5',\n",
    "    'eriica_k': 'steelblue'}\n",
    "\n",
    "subset = timeline[\n",
    "    timeline.first_id.isin(people) &\n",
    "    timeline.second_id.isin(people)]\n",
    "\n",
    "alt.Chart(subset) \\\n",
    "    .mark_point() \\\n",
    "    .encode(\n",
    "        x=alt.X('first_occurrence:T', axis=alt.Axis(title='first occurrence')),\n",
    "        y=alt.Y('second_occurrence:T', axis=alt.Axis(title='second occurrence')),\n",
    "        color=alt.condition(\n",
    "            'datum.first_occurrence == datum.second_occurrence',\n",
    "            alt.value('lightgray'),\n",
    "            'first_id:N',\n",
    "            legend=alt.Legend(title='first heard by'),\n",
    "            scale=alt.Scale(\n",
    "                domain=people,\n",
    "                range=[colors[p] for p in people])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('track_name', title='track'),\n",
    "            alt.Tooltip('first_occurrence:T', title='First', format='%Y_%m_%d'),\n",
    "            alt.Tooltip('second_occurrence', title='Next', format='%Y_%m_%d')]) \\\n",
    "    .properties(title='who listened first')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
